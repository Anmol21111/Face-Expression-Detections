{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b92d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ ENHANCED MULTI-FACE EXPRESSION DETECTION\n",
      "============================================================\n",
      "Features:\n",
      "‚Ä¢ Individual face tracking with IDs\n",
      "‚Ä¢ Stable expression detection (reduces flickering)\n",
      "‚Ä¢ Enhanced visualization with facial landmarks\n",
      "‚Ä¢ Real-time statistics and performance metrics\n",
      "‚Ä¢ Confidence threshold adjustment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Facial expression model loaded successfully!\n",
      "üöÄ Starting Enhanced Multi-Face Expression Detection\n",
      "‚úÖ Camera initialized successfully!\n",
      "\n",
      "üéÆ ENHANCED CONTROLS:\n",
      "   Q - Quit application\n",
      "   S - Save current frame\n",
      "   + - Increase confidence threshold\n",
      "   - - Decrease confidence threshold\n",
      "   C - Clear statistics\n",
      "   R - Reset face tracking\n",
      "üîª Confidence threshold: 0.55\n",
      "üîª Confidence threshold: 0.50\n",
      "üîª Confidence threshold: 0.45\n",
      "üîª Confidence threshold: 0.40\n",
      "üîª Confidence threshold: 0.35\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "üîª Confidence threshold: 0.30\n",
      "\n",
      "============================================================\n",
      "üìä DETAILED DETECTION STATISTICS\n",
      "============================================================\n",
      "Expression Breakdown:\n",
      "   happy     :  863 detections ( 50.8%)\n",
      "   neutral   :  324 detections ( 19.1%)\n",
      "   sad       :  290 detections ( 17.1%)\n",
      "   surprise  :  102 detections (  6.0%)\n",
      "   fear      :   65 detections (  3.8%)\n",
      "   angry     :   56 detections (  3.3%)\n",
      "\n",
      "üìà Total detections: 1700\n",
      "üë• Unique faces tracked: 62\n",
      "‚úÖ Enhanced detection stopped.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "class EnhancedExpressionDetector:\n",
    "    def __init__(self):\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "        self.expression_model = None\n",
    "        self.img_size = 48\n",
    "        self.class_names = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "        \n",
    "        # Enhanced colors for different expressions\n",
    "        self.expression_colors = {\n",
    "            'angry': (0, 0, 255),        # Red\n",
    "            'disgust': (0, 128, 0),      # Dark Green\n",
    "            'fear': (128, 0, 128),       # Purple\n",
    "            'happy': (0, 255, 255),      # Yellow\n",
    "            'neutral': (200, 200, 200),  # Light Gray\n",
    "            'sad': (255, 0, 0),          # Blue\n",
    "            'surprise': (0, 165, 255)    # Orange\n",
    "        }\n",
    "        \n",
    "        # Expression statistics and tracking\n",
    "        self.expression_stats = {expr: 0 for expr in self.class_names}\n",
    "        self.face_tracking = {}  # Track individual faces\n",
    "        self.next_face_id = 0\n",
    "        \n",
    "        # Confidence threshold\n",
    "        self.confidence_threshold = 0.6\n",
    "        \n",
    "        self.load_model()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the trained expression model\"\"\"\n",
    "        model_path = 'models/expression_model.h5'\n",
    "        if os.path.exists(model_path):\n",
    "            try:\n",
    "                self.expression_model = keras.models.load_model(model_path)\n",
    "                print(\"‚úÖ Facial expression model loaded successfully!\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading expression model: {e}\")\n",
    "        \n",
    "        print(\"‚ùå No trained expression model found.\")\n",
    "        print(\"üí° Please train the model first using the main menu\")\n",
    "        return False\n",
    "    \n",
    "    def preprocess_face(self, face_img):\n",
    "        \"\"\"Enhanced face preprocessing for better accuracy\"\"\"\n",
    "        # Resize to model input size\n",
    "        face_img = cv2.resize(face_img, (self.img_size, self.img_size))\n",
    "        \n",
    "        # Apply histogram equalization for better contrast\n",
    "        face_img = cv2.equalizeHist(face_img)\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        face_img = face_img.astype('float32') / 255.0\n",
    "        \n",
    "        # Reshape for model\n",
    "        face_img = np.expand_dims(face_img, axis=0)\n",
    "        face_img = np.expand_dims(face_img, axis=-1)\n",
    "        \n",
    "        return face_img\n",
    "    \n",
    "    def predict_expression(self, face_img):\n",
    "        \"\"\"Predict facial expression with enhanced confidence\"\"\"\n",
    "        if self.expression_model is None:\n",
    "            return \"neutral\", 0.5\n",
    "        \n",
    "        try:\n",
    "            # Preprocess face\n",
    "            processed_face = self.preprocess_face(face_img)\n",
    "            \n",
    "            # Predict\n",
    "            predictions = self.expression_model.predict(processed_face, verbose=0)\n",
    "            predicted_class = np.argmax(predictions[0])\n",
    "            confidence = predictions[0][predicted_class]\n",
    "            \n",
    "            expression = self.class_names[predicted_class]\n",
    "            \n",
    "            # Apply confidence threshold\n",
    "            if confidence < self.confidence_threshold:\n",
    "                return \"neutral\", confidence\n",
    "            \n",
    "            return expression, confidence\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Prediction error: {e}\")\n",
    "            return \"neutral\", 0.0\n",
    "    \n",
    "    def assign_face_id(self, face_rect, faces):\n",
    "        \"\"\"Assign or track face IDs for consistent tracking\"\"\"\n",
    "        x, y, w, h = face_rect\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        \n",
    "        # Calculate face area for size comparison\n",
    "        area = w * h\n",
    "        \n",
    "        # Check if this face matches any existing tracked face\n",
    "        min_distance = float('inf')\n",
    "        best_match_id = None\n",
    "        \n",
    "        for face_id, face_data in self.face_tracking.items():\n",
    "            last_center = face_data['center']\n",
    "            last_area = face_data['area']\n",
    "            \n",
    "            # Calculate distance and size difference\n",
    "            distance = np.sqrt((center_x - last_center[0])**2 + (center_y - last_center[1])**2)\n",
    "            area_ratio = min(area, last_area) / max(area, last_area)\n",
    "            \n",
    "            # If close enough and similar size, consider it the same face\n",
    "            if distance < 50 and area_ratio > 0.5:\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    best_match_id = face_id\n",
    "        \n",
    "        if best_match_id is not None:\n",
    "            # Update existing face\n",
    "            self.face_tracking[best_match_id].update({\n",
    "                'center': (center_x, center_y),\n",
    "                'area': area,\n",
    "                'last_seen': time.time()\n",
    "            })\n",
    "            return best_match_id\n",
    "        else:\n",
    "            # New face\n",
    "            face_id = self.next_face_id\n",
    "            self.face_tracking[face_id] = {\n",
    "                'center': (center_x, center_y),\n",
    "                'area': area,\n",
    "                'last_seen': time.time(),\n",
    "                'expression_history': []\n",
    "            }\n",
    "            self.next_face_id += 1\n",
    "            return face_id\n",
    "    \n",
    "    def cleanup_old_faces(self):\n",
    "        \"\"\"Remove faces that haven't been seen for a while\"\"\"\n",
    "        current_time = time.time()\n",
    "        faces_to_remove = []\n",
    "        \n",
    "        for face_id, face_data in self.face_tracking.items():\n",
    "            if current_time - face_data['last_seen'] > 2.0:  # 2 seconds\n",
    "                faces_to_remove.append(face_id)\n",
    "        \n",
    "        for face_id in faces_to_remove:\n",
    "            del self.face_tracking[face_id]\n",
    "    \n",
    "    def get_stable_expression(self, face_id, current_expression, confidence):\n",
    "        \"\"\"Get stable expression using history to reduce flickering\"\"\"\n",
    "        if face_id not in self.face_tracking:\n",
    "            return current_expression\n",
    "        \n",
    "        # Add current expression to history\n",
    "        self.face_tracking[face_id]['expression_history'].append(\n",
    "            (current_expression, confidence, time.time())\n",
    "        )\n",
    "        \n",
    "        # Keep only recent history (last 1 second)\n",
    "        current_time = time.time()\n",
    "        self.face_tracking[face_id]['expression_history'] = [\n",
    "            (expr, conf, t) for expr, conf, t in self.face_tracking[face_id]['expression_history']\n",
    "            if current_time - t < 1.0\n",
    "        ]\n",
    "        \n",
    "        # If we have enough history, use the most frequent expression\n",
    "        if len(self.face_tracking[face_id]['expression_history']) >= 3:\n",
    "            expressions = [expr for expr, conf, t in self.face_tracking[face_id]['expression_history']]\n",
    "            # Count occurrences\n",
    "            from collections import Counter\n",
    "            expr_counter = Counter(expressions)\n",
    "            most_common = expr_counter.most_common(1)[0][0]\n",
    "            return most_common\n",
    "        \n",
    "        return current_expression\n",
    "    \n",
    "    def draw_enhanced_face_detection(self, frame, face_rect, expression, confidence, face_id):\n",
    "        \"\"\"Draw enhanced face detection with expression info\"\"\"\n",
    "        x, y, w, h = face_rect\n",
    "        color = self.expression_colors.get(expression, (255, 255, 255))\n",
    "        \n",
    "        # Draw main bounding box with thickness based on confidence\n",
    "        thickness = 2 + int(confidence * 3)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, thickness)\n",
    "        \n",
    "        # Draw face ID\n",
    "        id_text = f\"ID: {face_id}\"\n",
    "        cv2.putText(frame, id_text, (x, y - 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        # Draw expression label with background\n",
    "        label_text = f\"{expression.upper()}\"\n",
    "        confidence_text = f\"Conf: {confidence:.2f}\"\n",
    "        \n",
    "        # Main label background\n",
    "        (text_width, text_height), _ = cv2.getTextSize(\n",
    "            label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2\n",
    "        )\n",
    "        \n",
    "        cv2.rectangle(frame, \n",
    "                     (x, y - text_height - 40),\n",
    "                     (x + text_width + 10, y - 10),\n",
    "                     color, -1)\n",
    "        \n",
    "        # Expression text\n",
    "        cv2.putText(frame, label_text, (x + 5, y - 25),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        # Confidence text\n",
    "        cv2.putText(frame, confidence_text, (x + 5, y - 10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "        \n",
    "        # Confidence bar\n",
    "        bar_width = w\n",
    "        bar_height = 6\n",
    "        confidence_width = int(bar_width * confidence)\n",
    "        \n",
    "        # Bar background\n",
    "        cv2.rectangle(frame, \n",
    "                     (x, y + h + 5),\n",
    "                     (x + bar_width, y + h + 5 + bar_height),\n",
    "                     (50, 50, 50), -1)\n",
    "        \n",
    "        # Confidence level\n",
    "        cv2.rectangle(frame, \n",
    "                     (x, y + h + 5),\n",
    "                     (x + confidence_width, y + h + 5 + bar_height),\n",
    "                     color, -1)\n",
    "        \n",
    "        # Face center point\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        cv2.circle(frame, (center_x, center_y), 3, color, -1)\n",
    "        \n",
    "        # Draw facial landmarks (approximate)\n",
    "        self.draw_facial_landmarks(frame, x, y, w, h, expression)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def draw_facial_landmarks(self, frame, x, y, w, h, expression):\n",
    "        \"\"\"Draw approximate facial landmarks based on expression\"\"\"\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        \n",
    "        # Eye positions\n",
    "        left_eye = (center_x - w//4, center_y - h//6)\n",
    "        right_eye = (center_x + w//4, center_y - h//6)\n",
    "        \n",
    "        # Mouth position\n",
    "        mouth_y = center_y + h//4\n",
    "        \n",
    "        # Draw eyes based on expression\n",
    "        if expression == 'happy':\n",
    "            # Happy eyes (curved up)\n",
    "            cv2.ellipse(frame, left_eye, (w//12, h//20), 0, 0, 180, (255, 255, 255), 1)\n",
    "            cv2.ellipse(frame, right_eye, (w//12, h//20), 0, 0, 180, (255, 255, 255), 1)\n",
    "            # Smile\n",
    "            cv2.ellipse(frame, (center_x, mouth_y), (w//4, h//10), 0, 0, 180, (255, 255, 255), 2)\n",
    "        \n",
    "        elif expression == 'sad':\n",
    "            # Sad eyes\n",
    "            cv2.circle(frame, left_eye, w//20, (255, 255, 255), -1)\n",
    "            cv2.circle(frame, right_eye, w//20, (255, 255, 255), -1)\n",
    "            # Frown\n",
    "            cv2.ellipse(frame, (center_x, mouth_y + h//20), (w//4, h//10), 0, 180, 360, (255, 255, 255), 2)\n",
    "        \n",
    "        elif expression == 'surprise':\n",
    "            # Surprised eyes (larger)\n",
    "            cv2.circle(frame, left_eye, w//15, (255, 255, 255), -1)\n",
    "            cv2.circle(frame, right_eye, w//15, (255, 255, 255), -1)\n",
    "            # Open mouth\n",
    "            cv2.circle(frame, (center_x, mouth_y), w//10, (255, 255, 255), 2)\n",
    "        \n",
    "        elif expression == 'angry':\n",
    "            # Angry eyes (slanted)\n",
    "            cv2.line(frame, (left_eye[0]-w//20, left_eye[1]-h//20), \n",
    "                    (left_eye[0]+w//20, left_eye[1]+h//20), (255, 255, 255), 2)\n",
    "            cv2.line(frame, (right_eye[0]-w//20, right_eye[1]-h//20), \n",
    "                    (right_eye[0]+w//20, right_eye[1]+h//20), (255, 255, 255), 2)\n",
    "            # Angry mouth\n",
    "            cv2.line(frame, (center_x-w//4, mouth_y), (center_x+w//4, mouth_y), (255, 255, 255), 2)\n",
    "        \n",
    "        else:  # neutral, disgust, fear\n",
    "            # Normal eyes and mouth\n",
    "            cv2.circle(frame, left_eye, w//25, (255, 255, 255), -1)\n",
    "            cv2.circle(frame, right_eye, w//25, (255, 255, 255), -1)\n",
    "            cv2.line(frame, (center_x-w//4, mouth_y), (center_x+w//4, mouth_y), (255, 255, 255), 2)\n",
    "    \n",
    "    def draw_enhanced_info_panel(self, frame, detected_faces, fps, processing_time):\n",
    "        \"\"\"Draw enhanced information panel\"\"\"\n",
    "        panel_width = 350\n",
    "        panel_height = frame.shape[0]\n",
    "        \n",
    "        # Create semi-transparent panel\n",
    "        overlay = frame.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (panel_width, panel_height), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.8, frame, 0.2, 0, frame)\n",
    "        \n",
    "        y_offset = 30\n",
    "        line_height = 25\n",
    "        \n",
    "        # Title\n",
    "        cv2.putText(frame, \"üé≠ MULTI-FACE EXPRESSION DETECTOR\", (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        y_offset += line_height * 2\n",
    "        \n",
    "        # Performance info\n",
    "        cv2.putText(frame, f\"üìä FPS: {fps:.1f}\", (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        y_offset += line_height\n",
    "        \n",
    "        cv2.putText(frame, f\"‚è±Ô∏è Processing: {processing_time:.1f}ms\", (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        y_offset += line_height\n",
    "        \n",
    "        cv2.putText(frame, f\"üë• Faces Detected: {len(detected_faces)}\", (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        y_offset += line_height\n",
    "        \n",
    "        cv2.putText(frame, f\"üéØ Confidence: {self.confidence_threshold:.1f}\", (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        y_offset += line_height * 2\n",
    "        \n",
    "        # Current face detections\n",
    "        if detected_faces:\n",
    "            cv2.putText(frame, \"CURRENT FACES:\", (10, y_offset),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "            y_offset += line_height\n",
    "            \n",
    "            for face_data in detected_faces:\n",
    "                face_id = face_data['face_id']\n",
    "                expression = face_data['expression']\n",
    "                confidence = face_data['confidence']\n",
    "                color = self.expression_colors.get(expression, (255, 255, 255))\n",
    "                \n",
    "                face_text = f\"Face {face_id}: {expression} ({confidence:.2f})\"\n",
    "                cv2.putText(frame, face_text, (10, y_offset),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "                y_offset += line_height\n",
    "        else:\n",
    "            cv2.putText(frame, \"No faces detected\", (10, y_offset),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)\n",
    "            y_offset += line_height\n",
    "        \n",
    "        y_offset += line_height\n",
    "        \n",
    "        # Expression statistics\n",
    "        cv2.putText(frame, \"EXPRESSION STATISTICS:\", (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "        y_offset += line_height\n",
    "        \n",
    "        total_detections = sum(self.expression_stats.values())\n",
    "        if total_detections > 0:\n",
    "            sorted_stats = sorted(self.expression_stats.items(), \n",
    "                                key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            for expr, count in sorted_stats[:5]:  # Top 5\n",
    "                if count > 0:\n",
    "                    percentage = (count / total_detections) * 100\n",
    "                    color = self.expression_colors.get(expr, (255, 255, 255))\n",
    "                    stat_text = f\"{expr}: {count} ({percentage:.1f}%)\"\n",
    "                    cv2.putText(frame, stat_text, (10, y_offset),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "                    y_offset += line_height\n",
    "        else:\n",
    "            cv2.putText(frame, \"No data yet\", (10, y_offset),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (100, 100, 100), 1)\n",
    "            y_offset += line_height\n",
    "        \n",
    "        # Color legend\n",
    "        y_offset = panel_height - 180\n",
    "        cv2.putText(frame, \"EXPRESSION COLORS:\", (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        y_offset += line_height\n",
    "        \n",
    "        for expr in self.class_names:\n",
    "            color = self.expression_colors.get(expr, (255, 255, 255))\n",
    "            cv2.putText(frame, f\"‚óè {expr}\", (10, y_offset),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.3, color, 1)\n",
    "            y_offset += 15\n",
    "        \n",
    "        # Controls help\n",
    "        y_offset = panel_height - 30\n",
    "        controls = \"Q:Quit  S:Save  +/-:Confidence  C:Clear\"\n",
    "        cv2.putText(frame, controls, (10, y_offset),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def detect_multiple_faces_real_time(self):\n",
    "        \"\"\"Enhanced real-time detection for multiple faces\"\"\"\n",
    "        if self.expression_model is None:\n",
    "            print(\"‚ùå Cannot start without a trained model.\")\n",
    "            return\n",
    "        \n",
    "        # Initialize camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"‚ùå Error: Could not open camera\")\n",
    "            return\n",
    "        \n",
    "        print(\"üöÄ Starting Enhanced Multi-Face Expression Detection\")\n",
    "        print(\"‚úÖ Camera initialized successfully!\")\n",
    "        print(\"\\nüéÆ ENHANCED CONTROLS:\")\n",
    "        print(\"   Q - Quit application\")\n",
    "        print(\"   S - Save current frame\")\n",
    "        print(\"   + - Increase confidence threshold\")\n",
    "        print(\"   - - Decrease confidence threshold\")\n",
    "        print(\"   C - Clear statistics\")\n",
    "        print(\"   R - Reset face tracking\")\n",
    "        \n",
    "        # Performance tracking\n",
    "        prev_time = time.time()\n",
    "        fps = 0\n",
    "        frame_count = 0\n",
    "        \n",
    "        try:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    print(\"‚ùå Failed to grab frame\")\n",
    "                    break\n",
    "                \n",
    "                # Calculate FPS\n",
    "                current_time = time.time()\n",
    "                fps = 1.0 / (current_time - prev_time)\n",
    "                prev_time = current_time\n",
    "                frame_count += 1\n",
    "                \n",
    "                # Flip frame horizontally for mirror effect\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                \n",
    "                detected_faces = []\n",
    "                processing_time = 0\n",
    "                \n",
    "                # Convert to grayscale for face detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Enhanced face detection with timing\n",
    "                start_time = time.time()\n",
    "                faces = self.face_cascade.detectMultiScale(\n",
    "                    gray, \n",
    "                    scaleFactor=1.1, \n",
    "                    minNeighbors=6, \n",
    "                    minSize=(80, 80),\n",
    "                    flags=cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "                \n",
    "                # Process each face individually\n",
    "                for (x, y, w, h) in faces:\n",
    "                    # Extract face ROI\n",
    "                    face_roi = gray[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Assign face ID for tracking\n",
    "                    face_id = self.assign_face_id((x, y, w, h), faces)\n",
    "                    \n",
    "                    # Predict expression\n",
    "                    expression, confidence = self.predict_expression(face_roi)\n",
    "                    \n",
    "                    # Get stable expression using history\n",
    "                    stable_expression = self.get_stable_expression(face_id, expression, confidence)\n",
    "                    \n",
    "                    # Update statistics\n",
    "                    self.expression_stats[stable_expression] += 1\n",
    "                    \n",
    "                    # Store detection\n",
    "                    detected_faces.append({\n",
    "                        'face_id': face_id,\n",
    "                        'expression': stable_expression,\n",
    "                        'confidence': confidence,\n",
    "                        'bbox': (x, y, w, h)\n",
    "                    })\n",
    "                    \n",
    "                    # Draw enhanced detection for this face\n",
    "                    frame = self.draw_enhanced_face_detection(\n",
    "                        frame, (x, y, w, h), stable_expression, confidence, face_id\n",
    "                    )\n",
    "                \n",
    "                processing_time = (time.time() - start_time) * 1000\n",
    "                \n",
    "                # Clean up old faces\n",
    "                self.cleanup_old_faces()\n",
    "                \n",
    "                # Draw enhanced information panel\n",
    "                frame = self.draw_enhanced_info_panel(frame, detected_faces, fps, processing_time)\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Enhanced Multi-Face Expression Detection', frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('s'):\n",
    "                    # Save current frame\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    filename = f\"multi_face_detection_{timestamp}.jpg\"\n",
    "                    cv2.imwrite(filename, frame)\n",
    "                    print(f\"üíæ Frame saved as: {filename}\")\n",
    "                elif key == ord('+'):\n",
    "                    # Increase confidence threshold\n",
    "                    self.confidence_threshold = min(0.9, self.confidence_threshold + 0.05)\n",
    "                    print(f\"üî∫ Confidence threshold: {self.confidence_threshold:.2f}\")\n",
    "                elif key == ord('-'):\n",
    "                    # Decrease confidence threshold\n",
    "                    self.confidence_threshold = max(0.3, self.confidence_threshold - 0.05)\n",
    "                    print(f\"üîª Confidence threshold: {self.confidence_threshold:.2f}\")\n",
    "                elif key == ord('c'):\n",
    "                    # Clear statistics\n",
    "                    self.expression_stats = {expr: 0 for expr in self.class_names}\n",
    "                    print(\"üìä Statistics cleared!\")\n",
    "                elif key == ord('r'):\n",
    "                    # Reset face tracking\n",
    "                    self.face_tracking = {}\n",
    "                    self.next_face_id = 0\n",
    "                    print(\"üîÑ Face tracking reset!\")\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n‚èπÔ∏è Detection stopped by user\")\n",
    "        \n",
    "        finally:\n",
    "            # Print final statistics\n",
    "            self.print_detailed_stats()\n",
    "            \n",
    "            # Cleanup\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"‚úÖ Enhanced detection stopped.\")\n",
    "    \n",
    "    def print_detailed_stats(self):\n",
    "        \"\"\"Print detailed detection statistics\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä DETAILED DETECTION STATISTICS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_detections = sum(self.expression_stats.values())\n",
    "        \n",
    "        if total_detections > 0:\n",
    "            print(\"Expression Breakdown:\")\n",
    "            for expr, count in sorted(self.expression_stats.items(), key=lambda x: x[1], reverse=True):\n",
    "                if count > 0:\n",
    "                    percentage = (count / total_detections) * 100\n",
    "                    print(f\"   {expr:10}: {count:4} detections ({percentage:5.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nüìà Total detections: {total_detections}\")\n",
    "            print(f\"üë• Unique faces tracked: {self.next_face_id}\")\n",
    "        else:\n",
    "            print(\"   No expressions detected during this session.\")\n",
    "\n",
    "def main():\n",
    "    print(\"üé≠ ENHANCED MULTI-FACE EXPRESSION DETECTION\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Features:\")\n",
    "    print(\"‚Ä¢ Individual face tracking with IDs\")\n",
    "    print(\"‚Ä¢ Stable expression detection (reduces flickering)\")\n",
    "    print(\"‚Ä¢ Enhanced visualization with facial landmarks\")\n",
    "    print(\"‚Ä¢ Real-time statistics and performance metrics\")\n",
    "    print(\"‚Ä¢ Confidence threshold adjustment\")\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = EnhancedExpressionDetector()\n",
    "    \n",
    "    # Start enhanced detection\n",
    "    detector.detect_multiple_faces_real_time()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103ac3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f281e0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
