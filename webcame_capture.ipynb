{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3325aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Facial Expression Dataset Collector...\n",
      "üé≠ Facial Expression Dataset Collector\n",
      "==================================================\n",
      "\n",
      "üéÆ CONTROLS:\n",
      "   1 - Angry\n",
      "   2 - Disgust\n",
      "   3 - Fear\n",
      "   4 - Happy/Smile\n",
      "   5 - Neutral\n",
      "   6 - Sad\n",
      "   7 - Surprise\n",
      "   SPACE - Capture image\n",
      "   Q - Quit\n",
      "   Ctrl+C - Emergency quit\n",
      "\n",
      "üí° Make different facial expressions and press SPACE to capture!\n",
      "üìÅ Current expression: neutral\n",
      "üìù Changed expression to: angry\n",
      "üìù Changed expression to: fear\n",
      "üìù Changed expression to: happy\n",
      "üìù Changed expression to: neutral\n",
      "üìù Changed expression to: sad\n",
      "üìù Changed expression to: surprise\n",
      "üìù Changed expression to: disgust\n",
      "üìù Changed expression to: angry\n",
      "üìù Changed expression to: disgust\n",
      "üìù Changed expression to: fear\n",
      "üìù Changed expression to: happy\n",
      "üìù Changed expression to: neutral\n",
      "üìù Changed expression to: sad\n",
      "üìù Changed expression to: surprise\n",
      "\n",
      "‚úÖ Dataset collection complete!\n",
      "üìä Total images captured: 28709\n",
      "   angry: 3995 images\n",
      "   disgust: 436 images\n",
      "   fear: 4097 images\n",
      "   happy: 7215 images\n",
      "   neutral: 4965 images\n",
      "   sad: 4830 images\n",
      "   surprise: 3171 images\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import signal\n",
    "import sys\n",
    "\n",
    "\n",
    "class DatasetCollector:\n",
    "    def __init__(self):\n",
    "        self.expressions = {\n",
    "            '1': 'angry',\n",
    "            '2': 'disgust',\n",
    "            '3': 'fear',\n",
    "            '4': 'happy',\n",
    "            '5': 'neutral',\n",
    "            '6': 'sad',\n",
    "            '7': 'surprise'\n",
    "        }\n",
    "        self.dataset_dir = 'dataset'\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "        self.current_expression = 'neutral'\n",
    "        self.counters = {expr: 0 for expr in self.expressions.values()}\n",
    "        self.cap = None\n",
    "        self.running = True\n",
    "\n",
    "        # Create dataset directories\n",
    "        for expression in self.expressions.values():\n",
    "            os.makedirs(f'{self.dataset_dir}/{expression}', exist_ok=True)\n",
    "            # Count existing images\n",
    "            existing_files = os.listdir(f'{self.dataset_dir}/{expression}')\n",
    "            self.counters[expression] = len([f for f in existing_files if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "\n",
    "        # Setup signal handler for graceful shutdown\n",
    "        signal.signal(signal.SIGINT, self.signal_handler)\n",
    "\n",
    "    def signal_handler(self, sig, frame):\n",
    "        \"\"\"Handle Ctrl+C gracefully\"\"\"\n",
    "        print(\"\\n\\nüõë Received interrupt signal. Shutting down gracefully...\")\n",
    "        self.running = False\n",
    "\n",
    "    def initialize_camera(self):\n",
    "        \"\"\"Initialize camera with error handling\"\"\"\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                # Try different camera indices\n",
    "                for i in range(1, 4):\n",
    "                    self.cap = cv2.VideoCapture(i)\n",
    "                    if self.cap.isOpened():\n",
    "                        print(f\"‚úÖ Camera found at index {i}\")\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"‚ùå No camera found!\")\n",
    "                    return False\n",
    "\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "            self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Camera initialization error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def capture_dataset(self):\n",
    "        \"\"\"Capture facial expression dataset from webcam\"\"\"\n",
    "        if not self.initialize_camera():\n",
    "            return\n",
    "\n",
    "        print(\"üé≠ Facial Expression Dataset Collector\")\n",
    "        print(\"=\" * 50)\n",
    "        print(\"\\nüéÆ CONTROLS:\")\n",
    "        print(\"   1 - Angry\")\n",
    "        print(\"   2 - Disgust\")\n",
    "        print(\"   3 - Fear\")\n",
    "        print(\"   4 - Happy/Smile\")\n",
    "        print(\"   5 - Neutral\")\n",
    "        print(\"   6 - Sad\")\n",
    "        print(\"   7 - Surprise\")\n",
    "        print(\"   SPACE - Capture image\")\n",
    "        print(\"   Q - Quit\")\n",
    "        print(\"   Ctrl+C - Emergency quit\")\n",
    "        print(\"\\nüí° Make different facial expressions and press SPACE to capture!\")\n",
    "        print(f\"üìÅ Current expression: {self.current_expression}\")\n",
    "\n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"‚ùå Failed to grab frame\")\n",
    "                    break\n",
    "\n",
    "                # Convert to grayscale for face detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detect faces\n",
    "                faces = self.face_cascade.detectMultiScale(gray, 1.3, 5, minSize=(100, 100))\n",
    "\n",
    "                # Draw face bounding box and info\n",
    "                for (x, y, w, h) in faces:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                    # Display expression info\n",
    "                    info_text = f\"Expression: {self.current_expression}\"\n",
    "                    count_text = f\"Count: {self.counters[self.current_expression]}\"\n",
    "\n",
    "                    cv2.putText(frame, info_text, (x, y - 50),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, count_text, (x, y - 20),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "                # Display instructions\n",
    "                cv2.putText(frame, f\"Current: {self.current_expression}\", (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "                cv2.putText(frame, \"Press 1-7 to change expression\", (10, 60),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                cv2.putText(frame, \"SPACE to capture, Q to quit\", (10, 85),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "                cv2.putText(frame, f\"Total captured: {sum(self.counters.values())}\", (10, 110),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "                cv2.imshow('Facial Expression Dataset Collector', frame)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key in [ord(str(i)) for i in range(1, 8)]:\n",
    "                    # Change expression\n",
    "                    self.current_expression = self.expressions[chr(key)]\n",
    "                    print(f\"üìù Changed expression to: {self.current_expression}\")\n",
    "                elif key == ord(' '):\n",
    "                    # Capture image when space is pressed and face is detected\n",
    "                    if len(faces) > 0:\n",
    "                        self.save_face_image(gray, faces[0])\n",
    "                    else:\n",
    "                        print(\"‚ùå No face detected! Please position your face in the frame.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during capture: {e}\")\n",
    "\n",
    "        finally:\n",
    "            self.cleanup()\n",
    "\n",
    "        print(f\"\\n‚úÖ Dataset collection complete!\")\n",
    "        print(f\"üìä Total images captured: {sum(self.counters.values())}\")\n",
    "        for expr, count in self.counters.items():\n",
    "            print(f\"   {expr}: {count} images\")\n",
    "\n",
    "    def save_face_image(self, gray_frame, face_rect):\n",
    "        \"\"\"Save cropped face image\"\"\"\n",
    "        try:\n",
    "            x, y, w, h = face_rect\n",
    "\n",
    "            # Expand the face region slightly\n",
    "            margin = 20\n",
    "            x = max(0, x - margin)\n",
    "            y = max(0, y - margin)\n",
    "            w = min(gray_frame.shape[1] - x, w + 2 * margin)\n",
    "            h = min(gray_frame.shape[0] - y, h + 2 * margin)\n",
    "\n",
    "            # Extract and resize face\n",
    "            face_img = gray_frame[y:y + h, x:x + w]\n",
    "            face_img = cv2.resize(face_img, (48, 48))\n",
    "\n",
    "            # Save image\n",
    "            filename = f\"{self.dataset_dir}/{self.current_expression}/{self.current_expression}_{self.counters[self.current_expression]:04d}.jpg\"\n",
    "            success = cv2.imwrite(filename, face_img)\n",
    "\n",
    "            if success:\n",
    "                self.counters[self.current_expression] += 1\n",
    "                print(f\"üíæ Saved: {filename}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Failed to save: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving image: {e}\")\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Cleanup resources\"\"\"\n",
    "        try:\n",
    "            if self.cap and self.cap.isOpened():\n",
    "                self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            # Additional cleanup to ensure windows close\n",
    "            for i in range(5):\n",
    "                cv2.waitKey(1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Cleanup warning: {e}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"üöÄ Starting Facial Expression Dataset Collector...\")\n",
    "    collector = DatasetCollector()\n",
    "    collector.capture_dataset()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086c448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
