{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970b6109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ADVANCED DATASET COLLECTOR - 5000 IMAGES TARGET\n",
      "This will help you create a comprehensive dataset with 5000+ images per expression\n",
      "Enter target images per expression (default 5000): 45000\n",
      "üìÅ Setting up directory structure for large dataset...\n",
      "üéØ Target: 45000 images per expression\n",
      "üìä Total target: 315,000 images\n",
      "üìà Loaded previous progress\n",
      "\n",
      "üìä CURRENT PROGRESS:\n",
      "   üìù angry       :     0/45000 (  0.0%)\n",
      "   üìù disgust     :     0/45000 (  0.0%)\n",
      "   üìù fear        :     0/45000 (  0.0%)\n",
      "   üìù happy       :     0/45000 (  0.0%)\n",
      "   üìù neutral     :     0/45000 (  0.0%)\n",
      "   üìù sad         :     0/45000 (  0.0%)\n",
      "   üìù surprise    :     0/45000 (  0.0%)\n",
      "\n",
      "üéØ Overall: 0/315,000 (0.0%)\n",
      "üöÄ ADVANCED DATASET COLLECTOR\n",
      "============================================================\n",
      "üéØ Target: 45,000 images per expression\n",
      "üíæ Location: large_dataset/\n",
      "üìä Current: neutral\n",
      "\n",
      "üéÆ ADVANCED CONTROLS:\n",
      "   1-7      - Change expression\n",
      "   SPACE    - Manual capture\n",
      "   A        - Toggle auto-capture\n",
      "   + / -    - Adjust auto-capture delay\n",
      "   S        - Save progress\n",
      "   P        - Show progress\n",
      "   Q        - Quit\n",
      "   Ctrl+C   - Emergency quit\n",
      "\n",
      "üí° TIPS:\n",
      "   - Use AUTO mode for bulk capture\n",
      "   - Vary lighting, angles, and distances\n",
      "   - Take breaks between expressions\n",
      "   - Save progress regularly\n",
      "‚è±Ô∏è  Capture delay: 0.6s\n",
      "‚è±Ô∏è  Capture delay: 0.7s\n",
      "‚è±Ô∏è  Capture delay: 0.8s\n",
      "‚è±Ô∏è  Capture delay: 0.9s\n",
      "‚è±Ô∏è  Capture delay: 1.0s\n",
      "‚è±Ô∏è  Capture delay: 1.1s\n",
      "‚è±Ô∏è  Capture delay: 1.2s\n",
      "‚è±Ô∏è  Capture delay: 1.3s\n",
      "‚è±Ô∏è  Capture delay: 1.4s\n",
      "‚è±Ô∏è  Capture delay: 1.5s\n",
      "‚è±Ô∏è  Capture delay: 1.6s\n",
      "‚è±Ô∏è  Capture delay: 1.7s\n",
      "‚è±Ô∏è  Capture delay: 1.8s\n",
      "‚è±Ô∏è  Capture delay: 1.9s\n",
      "‚è±Ô∏è  Capture delay: 2.0s\n",
      "‚è±Ô∏è  Capture delay: 2.1s\n",
      "‚è±Ô∏è  Capture delay: 2.2s\n",
      "‚è±Ô∏è  Capture delay: 2.3s\n",
      "‚è±Ô∏è  Capture delay: 2.4s\n",
      "‚è±Ô∏è  Capture delay: 2.5s\n",
      "‚è±Ô∏è  Capture delay: 2.6s\n",
      "‚è±Ô∏è  Capture delay: 2.7s\n",
      "‚è±Ô∏è  Capture delay: 2.8s\n",
      "‚è±Ô∏è  Capture delay: 2.9s\n",
      "‚è±Ô∏è  Capture delay: 2.8s\n",
      "‚è±Ô∏è  Capture delay: 2.7s\n",
      "‚è±Ô∏è  Capture delay: 2.6s\n",
      "‚è±Ô∏è  Capture delay: 2.5s\n",
      "‚è±Ô∏è  Capture delay: 2.4s\n",
      "‚è±Ô∏è  Capture delay: 2.3s\n",
      "‚è±Ô∏è  Capture delay: 2.2s\n",
      "‚è±Ô∏è  Capture delay: 2.1s\n",
      "‚è±Ô∏è  Capture delay: 2.0s\n",
      "‚è±Ô∏è  Capture delay: 1.9s\n",
      "‚è±Ô∏è  Capture delay: 1.8s\n",
      "‚è±Ô∏è  Capture delay: 1.7s\n",
      "‚è±Ô∏è  Capture delay: 1.6s\n",
      "‚è±Ô∏è  Capture delay: 1.5s\n",
      "‚è±Ô∏è  Capture delay: 1.4s\n",
      "‚è±Ô∏è  Capture delay: 1.3s\n",
      "‚è±Ô∏è  Capture delay: 1.2s\n",
      "‚è±Ô∏è  Capture delay: 1.1s\n",
      "‚è±Ô∏è  Capture delay: 1.0s\n",
      "‚è±Ô∏è  Capture delay: 0.9s\n",
      "‚è±Ô∏è  Capture delay: 0.8s\n",
      "‚è±Ô∏è  Capture delay: 0.7s\n",
      "‚è±Ô∏è  Capture delay: 0.6s\n",
      "‚è±Ô∏è  Capture delay: 0.5s\n",
      "‚è±Ô∏è  Capture delay: 0.4s\n",
      "‚è±Ô∏è  Capture delay: 0.3s\n",
      "‚è±Ô∏è  Capture delay: 0.2s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "‚è±Ô∏è  Capture delay: 0.1s\n",
      "\n",
      "üìä CURRENT PROGRESS:\n",
      "   üìù angry       :     0/45000 (  0.0%)\n",
      "   üìù disgust     :     0/45000 (  0.0%)\n",
      "   üìù fear        :     0/45000 (  0.0%)\n",
      "   üìù happy       :     0/45000 (  0.0%)\n",
      "   üìù neutral     :     0/45000 (  0.0%)\n",
      "   üìù sad         :     0/45000 (  0.0%)\n",
      "   üìù surprise    :     0/45000 (  0.0%)\n",
      "\n",
      "üéØ Overall: 0/315,000 (0.0%)\n",
      "\n",
      "============================================================\n",
      "üìä DATASET COLLECTION COMPLETED\n",
      "============================================================\n",
      "üéØ Target per expression: 45,000\n",
      "üìà Total captured: 0/315,000\n",
      "üìÖ Session duration: 0h 1m\n",
      "\n",
      "üìã Expression Breakdown:\n",
      "   angry       :      0 images - üìù IN PROGRESS (  0.0%)\n",
      "   disgust     :      0 images - üìù IN PROGRESS (  0.0%)\n",
      "   fear        :      0 images - üìù IN PROGRESS (  0.0%)\n",
      "   happy       :      0 images - üìù IN PROGRESS (  0.0%)\n",
      "   neutral     :      0 images - üìù IN PROGRESS (  0.0%)\n",
      "   sad         :      0 images - üìù IN PROGRESS (  0.0%)\n",
      "   surprise    :      0 images - üìù IN PROGRESS (  0.0%)\n",
      "\n",
      "üíæ Progress saved to: progress/dataset_progress.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import threading\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class AdvancedDatasetCollector:\n",
    "    def __init__(self, target_images=5000):\n",
    "        self.expressions = {\n",
    "            '1': 'angry',\n",
    "            '2': 'disgust', \n",
    "            '3': 'fear',\n",
    "            '4': 'happy',\n",
    "            '5': 'neutral',\n",
    "            '6': 'sad',\n",
    "            '7': 'surprise'\n",
    "        }\n",
    "        self.dataset_dir = 'large_dataset'\n",
    "        self.target_images = target_images\n",
    "        self.face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "        )\n",
    "        self.current_expression = 'neutral'\n",
    "        self.counters = {expr: 0 for expr in self.expressions.values()}\n",
    "        self.cap = None\n",
    "        self.running = True\n",
    "        self.auto_capture = False\n",
    "        self.capture_delay = 0.5  # Delay between auto captures\n",
    "        self.last_capture_time = 0\n",
    "        self.session_stats = {\n",
    "            'start_time': None,\n",
    "            'total_captured': 0,\n",
    "            'session_duration': 0\n",
    "        }\n",
    "        \n",
    "        # Create dataset directories\n",
    "        self.setup_directories()\n",
    "        self.load_progress()\n",
    "        \n",
    "        # Setup signal handler\n",
    "        import signal\n",
    "        signal.signal(signal.SIGINT, self.signal_handler)\n",
    "    \n",
    "    def setup_directories(self):\n",
    "        \"\"\"Create directory structure for large dataset\"\"\"\n",
    "        print(\"üìÅ Setting up directory structure for large dataset...\")\n",
    "        \n",
    "        directories = [self.dataset_dir, 'models', 'progress']\n",
    "        \n",
    "        for directory in directories:\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "                print(f\"‚úÖ Created: {directory}/\")\n",
    "        \n",
    "        # Create expression subdirectories\n",
    "        for expression in self.expressions.values():\n",
    "            expr_path = f'{self.dataset_dir}/{expression}'\n",
    "            if not os.path.exists(expr_path):\n",
    "                os.makedirs(expr_path)\n",
    "        \n",
    "        print(f\"üéØ Target: {self.target_images} images per expression\")\n",
    "        print(f\"üìä Total target: {self.target_images * 7:,} images\")\n",
    "    \n",
    "    def load_progress(self):\n",
    "        \"\"\"Load progress from previous sessions\"\"\"\n",
    "        progress_file = 'progress/dataset_progress.json'\n",
    "        if os.path.exists(progress_file):\n",
    "            try:\n",
    "                with open(progress_file, 'r') as f:\n",
    "                    progress = json.load(f)\n",
    "                    self.counters = progress.get('counters', self.counters)\n",
    "                    print(\"üìà Loaded previous progress\")\n",
    "            except:\n",
    "                print(\"‚ùå Could not load progress file\")\n",
    "        \n",
    "        self.print_progress()\n",
    "    \n",
    "    def save_progress(self):\n",
    "        \"\"\"Save current progress\"\"\"\n",
    "        progress_file = 'progress/dataset_progress.json'\n",
    "        try:\n",
    "            with open(progress_file, 'w') as f:\n",
    "                json.dump({\n",
    "                    'counters': self.counters,\n",
    "                    'last_update': datetime.now().isoformat()\n",
    "                }, f, indent=2)\n",
    "        except:\n",
    "            print(\"‚ùå Could not save progress\")\n",
    "    \n",
    "    def print_progress(self):\n",
    "        \"\"\"Print current collection progress\"\"\"\n",
    "        print(\"\\nüìä CURRENT PROGRESS:\")\n",
    "        total_captured = sum(self.counters.values())\n",
    "        total_target = self.target_images * 7\n",
    "        \n",
    "        for expr in self.expressions.values():\n",
    "            percent = (self.counters[expr] / self.target_images) * 100\n",
    "            status = \"‚úÖ\" if self.counters[expr] >= self.target_images else \"üìù\"\n",
    "            print(f\"   {status} {expr:12}: {self.counters[expr]:5d}/{self.target_images} ({percent:5.1f}%)\")\n",
    "        \n",
    "        overall_percent = (total_captured / total_target) * 100\n",
    "        print(f\"\\nüéØ Overall: {total_captured:,}/{total_target:,} ({overall_percent:.1f}%)\")\n",
    "    \n",
    "    def signal_handler(self, sig, frame):\n",
    "        \"\"\"Handle Ctrl+C gracefully\"\"\"\n",
    "        print(\"\\n\\nüõë Received interrupt signal. Shutting down gracefully...\")\n",
    "        self.running = False\n",
    "    \n",
    "    def initialize_camera(self):\n",
    "        \"\"\"Initialize camera with multiple attempts\"\"\"\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                for i in range(1, 4):\n",
    "                    self.cap = cv2.VideoCapture(i)\n",
    "                    if self.cap.isOpened():\n",
    "                        print(f\"‚úÖ Camera found at index {i}\")\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"‚ùå No camera found!\")\n",
    "                    return False\n",
    "            \n",
    "            # Set camera properties\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)  # Higher resolution\n",
    "            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "            self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "            self.cap.set(cv2.CAP_PROP_AUTOFOCUS, 1)\n",
    "            self.cap.set(cv2.CAP_PROP_BRIGHTNESS, 0.5)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Camera initialization error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def enhance_image_quality(self, image):\n",
    "        \"\"\"Enhance image quality for better training\"\"\"\n",
    "        # Apply histogram equalization\n",
    "        if len(image.shape) == 2:  # Grayscale\n",
    "            image = cv2.equalizeHist(image)\n",
    "        else:  # Color\n",
    "            # Convert to YUV and equalize Y channel\n",
    "            yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "            yuv[:,:,0] = cv2.equalizeHist(yuv[:,:,0])\n",
    "            image = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)\n",
    "        \n",
    "        # Apply slight sharpening\n",
    "        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "        image = cv2.filter2D(image, -1, kernel)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def capture_dataset(self):\n",
    "        \"\"\"Advanced dataset collection with batch processing\"\"\"\n",
    "        if not self.initialize_camera():\n",
    "            return\n",
    "        \n",
    "        self.session_stats['start_time'] = datetime.now()\n",
    "        \n",
    "        print(\"üöÄ ADVANCED DATASET COLLECTOR\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"üéØ Target: {self.target_images:,} images per expression\")\n",
    "        print(f\"üíæ Location: {self.dataset_dir}/\")\n",
    "        print(f\"üìä Current: {self.current_expression}\")\n",
    "        \n",
    "        print(\"\\nüéÆ ADVANCED CONTROLS:\")\n",
    "        print(\"   1-7      - Change expression\")\n",
    "        print(\"   SPACE    - Manual capture\")\n",
    "        print(\"   A        - Toggle auto-capture\")\n",
    "        print(\"   + / -    - Adjust auto-capture delay\")\n",
    "        print(\"   S        - Save progress\")\n",
    "        print(\"   P        - Show progress\")\n",
    "        print(\"   Q        - Quit\")\n",
    "        print(\"   Ctrl+C   - Emergency quit\")\n",
    "        \n",
    "        print(\"\\nüí° TIPS:\")\n",
    "        print(\"   - Use AUTO mode for bulk capture\")\n",
    "        print(\"   - Vary lighting, angles, and distances\")\n",
    "        print(\"   - Take breaks between expressions\")\n",
    "        print(\"   - Save progress regularly\")\n",
    "        \n",
    "        auto_capture_active = False\n",
    "        last_progress_save = time.time()\n",
    "        \n",
    "        try:\n",
    "            while self.running:\n",
    "                ret, frame = self.cap.read()\n",
    "                if not ret:\n",
    "                    print(\"‚ùå Failed to grab frame\")\n",
    "                    break\n",
    "                \n",
    "                # Enhance frame quality\n",
    "                frame = self.enhance_image_quality(frame)\n",
    "                \n",
    "                # Convert to grayscale for face detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Detect faces with multiple scales for better detection\n",
    "                faces = self.face_cascade.detectMultiScale(\n",
    "                    gray, \n",
    "                    scaleFactor=1.1, \n",
    "                    minNeighbors=5, \n",
    "                    minSize=(100, 100),\n",
    "                    flags=cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "                \n",
    "                # Process faces\n",
    "                for (x, y, w, h) in faces:\n",
    "                    # Draw enhanced bounding box\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "                    \n",
    "                    # Draw facial landmarks area\n",
    "                    cv2.circle(frame, (x + w//2, y + h//3), 5, (255, 0, 0), -1)  # Nose\n",
    "                    cv2.circle(frame, (x + w//3, y + h//3), 5, (255, 0, 0), -1)  # Left eye\n",
    "                    cv2.circle(frame, (x + 2*w//3, y + h//3), 5, (255, 0, 0), -1)  # Right eye\n",
    "                    cv2.ellipse(frame, (x + w//2, y + 2*h//3), (w//4, h//6), 0, 0, 360, (255, 0, 0), 2)  # Mouth\n",
    "                \n",
    "                # Auto-capture logic\n",
    "                current_time = time.time()\n",
    "                if auto_capture_active and len(faces) > 0:\n",
    "                    if current_time - self.last_capture_time >= self.capture_delay:\n",
    "                        if self.counters[self.current_expression] < self.target_images:\n",
    "                            self.save_face_image(gray, faces[0])\n",
    "                            self.last_capture_time = current_time\n",
    "                        else:\n",
    "                            print(f\"‚úÖ Target reached for {self.current_expression}\")\n",
    "                            auto_capture_active = False\n",
    "                \n",
    "                # Display information overlay\n",
    "                self.draw_info_overlay(frame, auto_capture_active, len(faces))\n",
    "                \n",
    "                # Display frame\n",
    "                cv2.imshow('Advanced Dataset Collector - 5000 Images Target', frame)\n",
    "                \n",
    "                # Handle keyboard input\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if not self.handle_keyboard_input(key, faces, gray):\n",
    "                    break\n",
    "                \n",
    "                # Auto-save progress every 30 seconds\n",
    "                if current_time - last_progress_save > 30:\n",
    "                    self.save_progress()\n",
    "                    last_progress_save = current_time\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during capture: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            self.cleanup()\n",
    "            self.print_final_stats()\n",
    "    \n",
    "    def draw_info_overlay(self, frame, auto_capture_active, face_count):\n",
    "        \"\"\"Draw comprehensive information overlay\"\"\"\n",
    "        # Main info\n",
    "        y_offset = 30\n",
    "        info_lines = [\n",
    "            f\"Expression: {self.current_expression}\",\n",
    "            f\"Progress: {self.counters[self.current_expression]}/{self.target_images}\",\n",
    "            f\"Auto-Capture: {'ON' if auto_capture_active else 'OFF'}\",\n",
    "            f\"Faces: {face_count}\",\n",
    "            f\"Delay: {self.capture_delay:.1f}s\"\n",
    "        ]\n",
    "        \n",
    "        for i, line in enumerate(info_lines):\n",
    "            color = (0, 255, 0) if i == 0 else (255, 255, 255)\n",
    "            cv2.putText(frame, line, (10, y_offset + i*25), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        # Progress bar\n",
    "        progress = self.counters[self.current_expression] / self.target_images\n",
    "        bar_width = 400\n",
    "        bar_height = 20\n",
    "        bar_x, bar_y = 10, 150\n",
    "        \n",
    "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (50, 50, 50), -1)\n",
    "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x + int(bar_width * progress), bar_y + bar_height), (0, 255, 0), -1)\n",
    "        cv2.putText(frame, f\"{progress*100:.1f}%\", (bar_x + bar_width + 10, bar_y + 15), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "        \n",
    "        # Controls help\n",
    "        controls_y = frame.shape[0] - 100\n",
    "        controls = [\n",
    "            \"1-7: Change Exp | SPACE: Manual | A: Auto\",\n",
    "            \"+/-: Delay | S: Save | P: Progress | Q: Quit\"\n",
    "        ]\n",
    "        \n",
    "        for i, control in enumerate(controls):\n",
    "            cv2.putText(frame, control, (10, controls_y + i*20), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "    \n",
    "    def handle_keyboard_input(self, key, faces, gray_frame):\n",
    "        \"\"\"Handle all keyboard inputs\"\"\"\n",
    "        if key == ord('q'):\n",
    "            return False\n",
    "        \n",
    "        elif key in [ord(str(i)) for i in range(1, 8)]:\n",
    "            self.current_expression = self.expressions[chr(key)]\n",
    "            print(f\"üìù Changed expression to: {self.current_expression}\")\n",
    "        \n",
    "        elif key == ord(' '):  # Space - manual capture\n",
    "            if len(faces) > 0 and self.counters[self.current_expression] < self.target_images:\n",
    "                self.save_face_image(gray_frame, faces[0])\n",
    "            else:\n",
    "                print(\"‚ùå No face detected or target reached!\")\n",
    "        \n",
    "        elif key == ord('a'):  # Toggle auto-capture\n",
    "            self.auto_capture = not self.auto_capture\n",
    "            status = \"ON\" if self.auto_capture else \"OFF\"\n",
    "            print(f\"ü§ñ Auto-capture: {status}\")\n",
    "            self.last_capture_time = time.time()\n",
    "        \n",
    "        elif key == ord('+'):  # Increase delay\n",
    "            self.capture_delay = min(5.0, self.capture_delay + 0.1)\n",
    "            print(f\"‚è±Ô∏è  Capture delay: {self.capture_delay:.1f}s\")\n",
    "        \n",
    "        elif key == ord('-'):  # Decrease delay\n",
    "            self.capture_delay = max(0.1, self.capture_delay - 0.1)\n",
    "            print(f\"‚è±Ô∏è  Capture delay: {self.capture_delay:.1f}s\")\n",
    "        \n",
    "        elif key == ord('s'):  # Save progress\n",
    "            self.save_progress()\n",
    "            print(\"üíæ Progress saved!\")\n",
    "        \n",
    "        elif key == ord('p'):  # Show progress\n",
    "            self.print_progress()\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def save_face_image(self, gray_frame, face_rect):\n",
    "        \"\"\"Save enhanced face image with quality checks\"\"\"\n",
    "        try:\n",
    "            x, y, w, h = face_rect\n",
    "            \n",
    "            # Quality checks\n",
    "            if w < 100 or h < 100:  # Face too small\n",
    "                print(\"‚ö†Ô∏è  Face too small, skipping...\")\n",
    "                return\n",
    "            \n",
    "            # Expand the face region with margin\n",
    "            margin = min(w, h) // 3  # Dynamic margin based on face size\n",
    "            x = max(0, x - margin)\n",
    "            y = max(0, y - margin)\n",
    "            w = min(gray_frame.shape[1] - x, w + 2 * margin)\n",
    "            h = min(gray_frame.shape[0] - y, h + 2 * margin)\n",
    "            \n",
    "            # Extract and enhance face\n",
    "            face_img = gray_frame[y:y+h, x:x+w]\n",
    "            \n",
    "            # Multiple resolutions for training\n",
    "            resolutions = [\n",
    "                (48, 48),    # Standard for training\n",
    "                (96, 96),    # Higher resolution\n",
    "                (64, 64)     # Medium resolution\n",
    "            ]\n",
    "            \n",
    "            for i, (width, height) in enumerate(resolutions):\n",
    "                resized_face = cv2.resize(face_img, (width, height))\n",
    "                \n",
    "                # Apply enhancement\n",
    "                resized_face = cv2.equalizeHist(resized_face)\n",
    "                \n",
    "                # Save with different names\n",
    "                if i == 0:\n",
    "                    filename = f\"{self.dataset_dir}/{self.current_expression}/{self.current_expression}_{self.counters[self.current_expression]:06d}.jpg\"\n",
    "                else:\n",
    "                    filename = f\"{self.dataset_dir}/{self.current_expression}/{self.current_expression}_{self.counters[self.current_expression]:06d}_{width}x{height}.jpg\"\n",
    "                \n",
    "                success = cv2.imwrite(filename, resized_face)\n",
    "                \n",
    "                if not success:\n",
    "                    print(f\"‚ùå Failed to save: {filename}\")\n",
    "                    return\n",
    "            \n",
    "            self.counters[self.current_expression] += 1\n",
    "            self.session_stats['total_captured'] += 1\n",
    "            \n",
    "            # Progress feedback\n",
    "            if self.counters[self.current_expression] % 100 == 0:\n",
    "                percent = (self.counters[self.current_expression] / self.target_images) * 100\n",
    "                print(f\"üìà {self.current_expression}: {self.counters[self.current_expression]}/{self.target_images} ({percent:.1f}%)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error saving image: {e}\")\n",
    "    \n",
    "    def print_final_stats(self):\n",
    "        \"\"\"Print final collection statistics\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä DATASET COLLECTION COMPLETED\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        total_captured = sum(self.counters.values())\n",
    "        total_target = self.target_images * 7\n",
    "        \n",
    "        print(f\"üéØ Target per expression: {self.target_images:,}\")\n",
    "        print(f\"üìà Total captured: {total_captured:,}/{total_target:,}\")\n",
    "        print(f\"üìÖ Session duration: {self.get_session_duration()}\")\n",
    "        \n",
    "        print(\"\\nüìã Expression Breakdown:\")\n",
    "        for expr in self.expressions.values():\n",
    "            percent = (self.counters[expr] / self.target_images) * 100\n",
    "            status = \"‚úÖ COMPLETE\" if self.counters[expr] >= self.target_images else \"üìù IN PROGRESS\"\n",
    "            print(f\"   {expr:12}: {self.counters[expr]:6,} images - {status} ({percent:5.1f}%)\")\n",
    "        \n",
    "        # Save final progress\n",
    "        self.save_progress()\n",
    "        print(f\"\\nüíæ Progress saved to: progress/dataset_progress.json\")\n",
    "    \n",
    "    def get_session_duration(self):\n",
    "        \"\"\"Calculate session duration\"\"\"\n",
    "        if self.session_stats['start_time']:\n",
    "            duration = datetime.now() - self.session_stats['start_time']\n",
    "            hours = duration.seconds // 3600\n",
    "            minutes = (duration.seconds % 3600) // 60\n",
    "            return f\"{hours}h {minutes}m\"\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Cleanup resources\"\"\"\n",
    "        try:\n",
    "            if self.cap and self.cap.isOpened():\n",
    "                self.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            # Additional cleanup\n",
    "            for i in range(5):\n",
    "                cv2.waitKey(1)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Cleanup warning: {e}\")\n",
    "\n",
    "def main():\n",
    "    print(\"üöÄ ADVANCED DATASET COLLECTOR - 5000 IMAGES TARGET\")\n",
    "    print(\"This will help you create a comprehensive dataset with 5000+ images per expression\")\n",
    "    \n",
    "    # Get target from user\n",
    "    try:\n",
    "        target = int(input(\"Enter target images per expression (default 5000): \") or \"5000\")\n",
    "    except:\n",
    "        target = 5000\n",
    "    \n",
    "    collector = AdvancedDatasetCollector(target_images=target)\n",
    "    collector.capture_dataset()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c9668",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
