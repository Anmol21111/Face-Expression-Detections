{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb65d260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ DATASET MANAGEMENT TOOL\n",
      "==================================================\n",
      "\n",
      "üéÆ OPTIONS:\n",
      "1. üìä Show dataset statistics\n",
      "2. üßπ Cleanup corrupt images\n",
      "3. üìÑ Generate dataset report\n",
      "4. üöÄ Start data collection\n",
      "0. ‚ùå Exit\n",
      "\n",
      "Enter your choice: 1\n",
      "üìä DATASET STATISTICS\n",
      "==================================================\n",
      "   ‚ö†Ô∏è  angry       :      0 images\n",
      "   ‚ö†Ô∏è  disgust     :      0 images\n",
      "   ‚ö†Ô∏è  fear        :      0 images\n",
      "   ‚ö†Ô∏è  happy       :      0 images\n",
      "   ‚ö†Ô∏è  neutral     :      0 images\n",
      "   ‚ö†Ô∏è  sad         :      0 images\n",
      "   ‚ö†Ô∏è  surprise    :      0 images\n",
      "\n",
      "üéØ Total images: 0\n",
      "üìà Average per expression: 0\n",
      "\n",
      "üîç QUALITY ANALYSIS\n",
      "   Dimensions found: {}\n",
      "\n",
      "üéÆ OPTIONS:\n",
      "1. üìä Show dataset statistics\n",
      "2. üßπ Cleanup corrupt images\n",
      "3. üìÑ Generate dataset report\n",
      "4. üöÄ Start data collection\n",
      "0. ‚ùå Exit\n",
      "\n",
      "Enter your choice: 2\n",
      "\n",
      "üßπ CLEANING DATASET\n",
      "‚úÖ Removed 0 corrupt images\n",
      "\n",
      "üéÆ OPTIONS:\n",
      "1. üìä Show dataset statistics\n",
      "2. üßπ Cleanup corrupt images\n",
      "3. üìÑ Generate dataset report\n",
      "4. üöÄ Start data collection\n",
      "0. ‚ùå Exit\n",
      "\n",
      "Enter your choice: 3\n",
      "üìä DATASET STATISTICS\n",
      "==================================================\n",
      "   ‚ö†Ô∏è  angry       :      0 images\n",
      "   ‚ö†Ô∏è  disgust     :      0 images\n",
      "   ‚ö†Ô∏è  fear        :      0 images\n",
      "   ‚ö†Ô∏è  happy       :      0 images\n",
      "   ‚ö†Ô∏è  neutral     :      0 images\n",
      "   ‚ö†Ô∏è  sad         :      0 images\n",
      "   ‚ö†Ô∏è  surprise    :      0 images\n",
      "\n",
      "üéØ Total images: 0\n",
      "üìà Average per expression: 0\n",
      "\n",
      "üîç QUALITY ANALYSIS\n",
      "   Dimensions found: {}\n",
      "\n",
      "üìÑ Dataset report saved to: dataset_report.json\n",
      "\n",
      "üéÆ OPTIONS:\n",
      "1. üìä Show dataset statistics\n",
      "2. üßπ Cleanup corrupt images\n",
      "3. üìÑ Generate dataset report\n",
      "4. üöÄ Start data collection\n",
      "0. ‚ùå Exit\n",
      "\n",
      "Enter your choice: 4\n",
      "üöÄ Launching data collection...\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'batch_dataset_collector'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 182\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå Invalid choice\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 182\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 172\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m choice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ Launching data collection...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 172\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbatch_dataset_collector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdvancedDatasetCollector\n\u001b[0;32m    173\u001b[0m     collector \u001b[38;5;241m=\u001b[39m AdvancedDatasetCollector(target_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[0;32m    174\u001b[0m     collector\u001b[38;5;241m.\u001b[39mcapture_dataset()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'batch_dataset_collector'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class DatasetManager:\n",
    "    def __init__(self, dataset_dir='large_dataset'):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.expressions = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "    \n",
    "    def get_dataset_stats(self):\n",
    "        \"\"\"Get comprehensive dataset statistics\"\"\"\n",
    "        print(\"üìä DATASET STATISTICS\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        total_images = 0\n",
    "        expression_stats = {}\n",
    "        \n",
    "        for expression in self.expressions:\n",
    "            expr_path = os.path.join(self.dataset_dir, expression)\n",
    "            if os.path.exists(expr_path):\n",
    "                images = [f for f in os.listdir(expr_path) \n",
    "                         if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                count = len(images)\n",
    "                expression_stats[expression] = count\n",
    "                total_images += count\n",
    "                \n",
    "                status = \"‚úÖ\" if count >= 5000 else \"‚ö†Ô∏è \"\n",
    "                print(f\"   {status} {expression:12}: {count:6,} images\")\n",
    "            else:\n",
    "                expression_stats[expression] = 0\n",
    "                print(f\"   ‚ùå {expression:12}: 0 images\")\n",
    "        \n",
    "        print(f\"\\nüéØ Total images: {total_images:,}\")\n",
    "        print(f\"üìà Average per expression: {total_images/7:,.0f}\")\n",
    "        \n",
    "        # Quality analysis\n",
    "        self.analyze_quality()\n",
    "        \n",
    "        return expression_stats\n",
    "    \n",
    "    def analyze_quality(self):\n",
    "        \"\"\"Analyze image quality and dimensions\"\"\"\n",
    "        print(\"\\nüîç QUALITY ANALYSIS\")\n",
    "        \n",
    "        dimensions = {}\n",
    "        quality_issues = 0\n",
    "        \n",
    "        for expression in self.expressions[:1]:  # Sample first expression\n",
    "            expr_path = os.path.join(self.dataset_dir, expression)\n",
    "            if not os.path.exists(expr_path):\n",
    "                continue\n",
    "                \n",
    "            images = [f for f in os.listdir(expr_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:10]  # Sample 10 images\n",
    "            \n",
    "            for img_file in images:\n",
    "                img_path = os.path.join(expr_path, img_file)\n",
    "                try:\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        h, w = img.shape[:2]\n",
    "                        dim_key = f\"{w}x{h}\"\n",
    "                        dimensions[dim_key] = dimensions.get(dim_key, 0) + 1\n",
    "                        \n",
    "                        # Check for very dark or very bright images\n",
    "                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                        avg_brightness = np.mean(gray)\n",
    "                        if avg_brightness < 30 or avg_brightness > 220:\n",
    "                            quality_issues += 1\n",
    "                except:\n",
    "                    quality_issues += 1\n",
    "        \n",
    "        print(\"   Dimensions found:\", dict(list(dimensions.items())[:3]))\n",
    "        if quality_issues > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Potential quality issues: {quality_issues} images\")\n",
    "    \n",
    "    def cleanup_dataset(self):\n",
    "        \"\"\"Remove corrupt or invalid images\"\"\"\n",
    "        print(\"\\nüßπ CLEANING DATASET\")\n",
    "        \n",
    "        removed_count = 0\n",
    "        \n",
    "        for expression in self.expressions:\n",
    "            expr_path = os.path.join(self.dataset_dir, expression)\n",
    "            if not os.path.exists(expr_path):\n",
    "                continue\n",
    "                \n",
    "            images = [f for f in os.listdir(expr_path) \n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            for img_file in images:\n",
    "                img_path = os.path.join(expr_path, img_file)\n",
    "                try:\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        os.remove(img_path)\n",
    "                        removed_count += 1\n",
    "                        print(f\"   Removed corrupt: {img_file}\")\n",
    "                except:\n",
    "                    os.remove(img_path)\n",
    "                    removed_count += 1\n",
    "        \n",
    "        print(f\"‚úÖ Removed {removed_count} corrupt images\")\n",
    "    \n",
    "    def create_dataset_report(self):\n",
    "        \"\"\"Create a comprehensive dataset report\"\"\"\n",
    "        stats = self.get_dataset_stats()\n",
    "        \n",
    "        report = {\n",
    "            'generated_date': datetime.now().isoformat(),\n",
    "            'dataset_location': self.dataset_dir,\n",
    "            'total_images': sum(stats.values()),\n",
    "            'expression_stats': stats,\n",
    "            'recommendations': self.get_recommendations(stats)\n",
    "        }\n",
    "        \n",
    "        # Save report\n",
    "        with open('dataset_report.json', 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nüìÑ Dataset report saved to: dataset_report.json\")\n",
    "        return report\n",
    "    \n",
    "    def get_recommendations(self, stats):\n",
    "        \"\"\"Get recommendations based on dataset stats\"\"\"\n",
    "        recommendations = []\n",
    "        total = sum(stats.values())\n",
    "        \n",
    "        if total < 1000:\n",
    "            recommendations.append(\"üö® Dataset is very small. Aim for at least 1000 images per expression.\")\n",
    "        elif total < 10000:\n",
    "            recommendations.append(\"üí° Consider collecting more data for better model performance.\")\n",
    "        \n",
    "        # Check balance\n",
    "        avg = total / 7\n",
    "        for expr, count in stats.items():\n",
    "            if count < avg * 0.5:\n",
    "                recommendations.append(f\"‚ö†Ô∏è  {expr} has significantly fewer images than average\")\n",
    "        \n",
    "        if not recommendations:\n",
    "            recommendations.append(\"‚úÖ Dataset looks well-balanced and sufficient for training.\")\n",
    "        \n",
    "        return recommendations\n",
    "\n",
    "def main():\n",
    "    print(\"üé≠ DATASET MANAGEMENT TOOL\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    manager = DatasetManager()\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nüéÆ OPTIONS:\")\n",
    "        print(\"1. üìä Show dataset statistics\")\n",
    "        print(\"2. üßπ Cleanup corrupt images\")\n",
    "        print(\"3. üìÑ Generate dataset report\")\n",
    "        print(\"4. üöÄ Start data collection\")\n",
    "        print(\"0. ‚ùå Exit\")\n",
    "        \n",
    "        choice = input(\"\\nEnter your choice: \").strip()\n",
    "        \n",
    "        if choice == '1':\n",
    "            manager.get_dataset_stats()\n",
    "        elif choice == '2':\n",
    "            manager.cleanup_dataset()\n",
    "        elif choice == '3':\n",
    "            manager.create_dataset_report()\n",
    "        elif choice == '4':\n",
    "            print(\"üöÄ Launching data collection...\")\n",
    "            from batch_dataset_collector import AdvancedDatasetCollector\n",
    "            collector = AdvancedDatasetCollector(target_images=5000)\n",
    "            collector.capture_dataset()\n",
    "        elif choice == '0':\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Invalid choice\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2b5496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
